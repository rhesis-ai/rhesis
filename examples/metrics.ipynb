{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe08bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rhesis.sdk.metrics.constants import ThresholdOperator\n",
    "from rhesis.sdk.metrics.providers.native.categorical_judge import (\n",
    "    # Example usage of RhesisPromptMetricCategorical\n",
    "    CategoricalJudge,\n",
    ")\n",
    "from rhesis.sdk.metrics.providers.native.numeric_judge import (\n",
    "    NumericJudge,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e90b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a categorical metric for evaluating response quality\n",
    "metric = CategoricalJudge(\n",
    "    name=\"response_quality_evaluator\",\n",
    "    evaluation_prompt=(\n",
    "        \"Evaluate the quality of the response based on accuracy, completeness, and helpfulness.\"\n",
    "    ),\n",
    "    evaluation_steps=(\n",
    "        \"1. Check if the response directly answers the question\\n\"\n",
    "        \"2. Verify the information is accurate\\n\"\n",
    "        \"3. Assess if the response is complete and helpful\"\n",
    "    ),\n",
    "    reasoning=(\n",
    "        \"A good response should be accurate, complete, and directly \"\n",
    "        \"address the user's question.\"\n",
    "    ),\n",
    "    categories=[\"poor\", \"fair\", \"good\", \"perfect\"],\n",
    "    passing_categories=[\n",
    "        \"good\",\n",
    "        \"perfect\",\n",
    "    ],  # Only \"good\" and \"perfect\" are considered passing\n",
    "    evaluation_examples=(\n",
    "        \"Example: Question: 'What is Python?' \"\n",
    "        \"Good response: 'Python is a programming language...' \"\n",
    "        \"Poor response: 'I don't know.'\"\n",
    "    ),\n",
    "    model=\"gemini\",  # Optional: specify the model to use\n",
    ")\n",
    "\n",
    "# Example evaluation\n",
    "input_query = \"What is machine learning?\"\n",
    "system_output = (\n",
    "    \"Machine learning is a subset of artificial intelligence that enables computers to \"\n",
    "    \"learn and improve from experience without being explicitly programmed.\"\n",
    ")\n",
    "expected_output = (\n",
    "    \"Machine learning is a field of AI that focuses on algorithms that can learn from data.\"\n",
    ")\n",
    "\n",
    "# Evaluate the response\n",
    "result = metric.evaluate(\n",
    "    input=input_query,\n",
    "    output=system_output,\n",
    "    expected_output=expected_output,\n",
    "    context=[\"AI and machine learning concepts\", \"Computer science fundamentals\"],\n",
    ")\n",
    "\n",
    "print(f\"Score: {result.score}\")\n",
    "print(f\"Is Successful: {result.details['is_successful']}\")\n",
    "print(f\"Reason: {result.details['reason']}\")\n",
    "print(f\"Threshold: {result.details['threshold']}\")\n",
    "print(f\"Score Range: {result.details['min_score']} - {result.details['max_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faca0ca",
   "metadata": {},
   "source": [
    "# Numerical Judge\n",
    "Example usage of NumericJudge for evaluating text quality.\n",
    "\n",
    "This example demonstrates how to create and use a numeric prompt metric\n",
    "to evaluate the quality of generated text responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a metric for evaluating answer quality\n",
    "metric = NumericJudge(\n",
    "    name=\"answer_quality_evaluator\",\n",
    "    evaluation_prompt=\"\"\"\n",
    "    Evaluate the quality of the provided answer based on the following criteria:\n",
    "    1. Accuracy: How correct and factual is the information?\n",
    "    2. Completeness: Does it fully address the question?\n",
    "    3. Clarity: Is the answer clear and well-structured?\n",
    "    4. Relevance: How relevant is the answer to the question asked?\n",
    "    \"\"\",\n",
    "    evaluation_steps=\"\"\"\n",
    "    1. Read the question and the provided answer carefully\n",
    "    2. Check the answer against the expected output for accuracy\n",
    "    3. Assess completeness by checking if all aspects of the question are addressed\n",
    "    4. Evaluate clarity and structure of the response\n",
    "    5. Determine overall relevance to the original question\n",
    "    6. Assign a score from 0.0 to 1.0 based on these criteria\n",
    "    \"\"\",\n",
    "    reasoning=\"\"\"\n",
    "    Consider the context provided and compare the answer with the expected output.\n",
    "    A perfect answer (1.0) should be completely accurate, fully address the question,\n",
    "    be clearly written, and highly relevant. Lower scores should reflect deficiencies\n",
    "    in any of these areas.\n",
    "    \"\"\",\n",
    "    evaluation_examples=\"\"\"\n",
    "    Example 1:\n",
    "    Question: \"What is the capital of France?\"\n",
    "    Answer: \"Paris\"\n",
    "    Expected: \"The capital of France is Paris\"\n",
    "    Score: 0.9 (accurate but not complete)\n",
    "    \n",
    "    Example 2:\n",
    "    Question: \"What is the capital of France?\"\n",
    "    Answer: \"The capital of France is Paris, located in the north-central part of the country.\"\n",
    "    Expected: \"The capital of France is Paris\"\n",
    "    Score: 1.0 (accurate, complete, and well-structured)\n",
    "    \"\"\",\n",
    "    min_score=0.0,\n",
    "    max_score=1.0,\n",
    "    threshold=0.7,  # 70% threshold for success\n",
    "    threshold_operator=ThresholdOperator.GREATER_THAN_OR_EQUAL,\n",
    "    model=\"gemini\",\n",
    ")\n",
    "\n",
    "# Example data for evaluation\n",
    "test_input = \"What are the main benefits of renewable energy?\"\n",
    "test_output = (\n",
    "    \"Renewable energy sources like solar and wind power are clean, sustainable, \"\n",
    "    \"and help reduce greenhouse gas emissions. They also create jobs and reduce \"\n",
    "    \"dependence on fossil fuels.\"\n",
    ")\n",
    "expected_output = (\n",
    "    \"The main benefits of renewable energy include: 1) Environmental benefits - \"\n",
    "    \"reduced greenhouse gas emissions and air pollution, 2) Economic benefits - \"\n",
    "    \"job creation and energy cost savings, 3) Energy security - reduced \"\n",
    "    \"dependence on foreign fossil fuels, 4) Sustainability - inexhaustible \"\n",
    "    \"energy sources\"\n",
    ")\n",
    "\n",
    "result = metric.evaluate(input=test_input, output=test_output, expected_output=expected_output)\n",
    "\n",
    "print(f\"Score: {result.score}\")\n",
    "print(f\"Is Successful: {result.details['is_successful']}\")\n",
    "print(f\"Reason: {result.details['reason']}\")\n",
    "print(f\"Threshold: {result.details['threshold']}\")\n",
    "print(f\"Score Range: {result.details['min_score']} - {result.details['max_score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
