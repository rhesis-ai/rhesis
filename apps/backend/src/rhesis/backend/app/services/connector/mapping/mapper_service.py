"""Mapping service orchestrator with 4-tier priority system."""

from enum import Enum
from typing import Any, Dict

from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

from rhesis.backend.app.models.endpoint import Endpoint
from rhesis.backend.app.models.user import User
from rhesis.backend.logging import logger

from .auto_mapper import AutoMapper
from .llm_mapper import LLMMapper


class MappingSource(str, Enum):
    """
    Source of endpoint mappings indicating how they were generated.

    The source indicates the origin and reliability of the mappings, following
    a 4-tier priority system where higher priority sources override lower ones.

    Priority order (highest to lowest):
    1. SDK_MANUAL - Explicit mappings from developer via @endpoint decorator (100% reliable)
    2. SDK_HYBRID - Hybrid: developer manual + auto-generated (high reliability)
    3. PREVIOUSLY_SAVED - Previously saved mappings, preserved to avoid overwriting manual edits
    4. AUTO_MAPPED - Heuristic-based pattern matching (reliable for standard names)
    5. LLM_GENERATED - AI-inferred mappings when patterns fail (best-effort fallback)
    """

    SDK_MANUAL = "sdk_manual"
    """
    Developer explicitly specified both request and response mappings via @endpoint decorator.
    """

    SDK_HYBRID = "sdk_hybrid"
    """
    Hybrid approach: Developer specified one mapping via @collaborate (request OR response),
    the other was auto-generated. Combines manual developer input with automatic inference.
    """

    PREVIOUSLY_SAVED = "previously_saved"
    """
    Mappings loaded from database and preserved on SDK reconnection.
    Used to avoid overwriting manual edits that users may have made via the UI.
    Has should_update=False to prevent re-generation on subsequent syncs.
    """

    AUTO_MAPPED = "auto_mapped"
    """Mappings detected via heuristic pattern matching (e.g., 'input' param â†’ input field)."""

    LLM_GENERATED = "llm_generated"
    """Mappings generated by LLM when auto-mapping confidence is low (< 0.7)."""


class MappingResult(BaseModel):
    """Result of mapping generation with metadata."""

    request_mapping: Dict[str, Any] = Field(
        description="Jinja2 template mapping standard fields to function parameters"
    )
    response_mapping: Dict[str, Any] = Field(
        description="Mapping from function output to standard fields (supports nested dicts)"
    )
    source: MappingSource = Field(
        description=(
            "Origin of the mappings. Indicates how mappings were generated and their reliability. "
            "See MappingSource enum for detailed descriptions of each source type."
        )
    )
    confidence: float = Field(
        ge=0.0,
        le=1.0,
        description=(
            "Confidence score for the mappings (0.0-1.0). "
            "Higher values indicate more reliable mappings. "
            "Threshold: auto-mapping with confidence < 0.7 triggers LLM fallback."
        ),
    )
    should_update: bool = Field(
        description=(
            "Whether the endpoint should be updated with these mappings. "
            "False for existing_db source to preserve manual edits, True otherwise."
        )
    )
    reasoning: str = Field(
        default="",
        description=(
            "Human-readable explanation of mapping choices and source. "
            "Includes details about matched fields, confidence factors, or generation method."
        ),
    )


class MappingService:
    """Orchestrates mapping generation with 4-tier priority system."""

    def __init__(self):
        """Initialize mapping service with auto and LLM mappers."""
        self.auto_mapper = AutoMapper()
        self.llm_mapper = LLMMapper()

    def generate_or_use_existing(
        self,
        db: Session,
        user: User,
        endpoint: Endpoint,
        sdk_metadata: Dict[str, Any],
        function_data: Dict[str, Any],
    ) -> MappingResult:
        """
        Generate mappings with 4-tier priority system.

        Priority:
        1. SDK manual mappings (from @endpoint decorator)
        2. Existing DB mappings (preserve manual edits)
        3. Auto-mapping (heuristic-based)
        4. LLM fallback (when auto-mapping confidence < 0.7)

        Args:
            db: Database session
            user: User for language model access
            endpoint: Endpoint being synced
            sdk_metadata: Metadata from SDK registration
            function_data: Function information

        Returns:
            MappingResult with request_mapping, response_mapping, source, confidence,
            should_update flag, and reasoning
        """
        function_name = function_data.get("name", "unknown")

        # Priority 1: SDK manual mappings from @endpoint decorator
        sdk_request = sdk_metadata.get("request_mapping")
        sdk_response = sdk_metadata.get("response_mapping")

        # Allow partial manual mappings - use SDK provided ones and auto-generate the rest
        if sdk_request or sdk_response:
            logger.info(
                f"[{function_name}] Using SDK manual mappings "
                f"(request: {bool(sdk_request)}, response: {bool(sdk_response)})"
            )

            # If only partial mappings provided, generate the missing ones
            final_request_mapping = sdk_request
            final_response_mapping = sdk_response
            source = MappingSource.SDK_MANUAL

            if not final_request_mapping or not final_response_mapping:
                # Need to auto-generate missing mapping
                logger.info(f"[{function_name}] Auto-generating missing mapping component")
                auto_result = self.auto_mapper.generate_mappings(
                    function_name=function_name,
                    parameters=function_data.get("parameters", {}),
                    return_type=function_data.get("return_type", "any"),
                    description=sdk_metadata.get("description", ""),
                )

                if not final_request_mapping:
                    final_request_mapping = auto_result["request_mapping"]
                    source = MappingSource.SDK_HYBRID
                if not final_response_mapping:
                    final_response_mapping = auto_result["response_mapping"]
                    source = MappingSource.SDK_HYBRID

            return MappingResult(
                request_mapping=final_request_mapping,
                response_mapping=final_response_mapping,
                source=source,
                confidence=1.0,
                should_update=True,
                reasoning=(
                    "Explicit mappings from @endpoint decorator"
                    + (
                        " with auto-generated components"
                        if source == MappingSource.SDK_HYBRID
                        else ""
                    )
                ),
            )

        # Priority 2: Previously saved mappings (preserve manual edits on reconnection)
        if endpoint.request_mapping and endpoint.response_mapping:
            logger.info(
                f"[{function_name}] Using previously saved mappings (preserving manual edits)"
            )
            return MappingResult(
                request_mapping=endpoint.request_mapping,
                response_mapping=endpoint.response_mapping,
                source=MappingSource.PREVIOUSLY_SAVED,
                confidence=1.0,
                should_update=False,
                reasoning="Previously saved mappings preserved from database",
            )

        # Priority 3: Auto-mapping with heuristics
        logger.info(f"[{function_name}] Attempting auto-mapping")
        auto_result = self.auto_mapper.generate_mappings(
            function_name=function_name,
            parameters=function_data.get("parameters", {}),
            return_type=function_data.get("return_type", "any"),
            description=sdk_metadata.get("description", ""),
        )

        # Check if auto-mapping confidence is sufficient
        if auto_result["confidence"] >= 0.7:
            logger.info(
                f"[{function_name}] Auto-mapping successful "
                f"(confidence: {auto_result['confidence']:.2f})"
            )
            return MappingResult(
                request_mapping=auto_result["request_mapping"],
                response_mapping=auto_result["response_mapping"],
                source=MappingSource.AUTO_MAPPED,
                confidence=auto_result["confidence"],
                should_update=True,
                reasoning=(
                    f"Auto-detected from function signature. "
                    f"Matched: {auto_result['matched_fields']}"
                ),
            )

        # Priority 4: LLM fallback
        logger.info(
            f"[{function_name}] Auto-mapping confidence low "
            f"({auto_result['confidence']:.2f}), using LLM fallback"
        )

        llm_result = self.llm_mapper.generate_mappings(
            db=db,
            user=user,
            function_name=function_name,
            parameters=function_data.get("parameters", {}),
            return_type=function_data.get("return_type", "any"),
            description=sdk_metadata.get("description", ""),
        )

        return MappingResult(
            request_mapping=llm_result["request_mapping"],
            response_mapping=llm_result["response_mapping"],
            source=MappingSource.LLM_GENERATED,
            confidence=llm_result["confidence"],
            should_update=True,
            reasoning=llm_result.get("reasoning", "Generated by LLM"),
        )
