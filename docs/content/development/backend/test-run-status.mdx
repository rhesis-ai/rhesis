import { CodeBlock } from '@/components/CodeBlock'

# Test Run Status

This guide explains how test run statuses are determined and what they represent in the Rhesis backend.

## Overview

Test run statuses reflect **execution completion**, not test assertion results. A test run can be "Completed" even if all tests failed their assertions, as long as they executed successfully.

## Status Types

### COMPLETED

**Definition:** All tests executed successfully (regardless of pass/fail results)

**When assigned:**

- `execution_errors == 0` (all tests ran without errors)
- At least one test was present in the run

**Email status:**

- `"success"` if all tests passed
- `"failed"` if any tests failed

**Example scenarios:**

<CodeBlock filename="completed-scenarios.txt" language="text">
{`10 tests, 10 passed, 0 failed, 0 errors → COMPLETED (email: success)
10 tests, 7 passed, 3 failed, 0 errors → COMPLETED (email: failed)
10 tests, 0 passed, 10 failed, 0 errors → COMPLETED (email: failed)`}
</CodeBlock>

### PARTIAL

**Definition:** Incomplete execution - some tests executed, some couldn't

**When assigned:**

- `0 < execution_errors < total_tests`
- Mix of successfully executed tests and execution errors

**Email status:** `"partial"`

**Example scenarios:**

<CodeBlock filename="partial-scenarios.txt" language="text">
{`10 tests, 5 passed, 3 failed, 2 errors → PARTIAL
10 tests, 8 passed, 0 failed, 2 errors → PARTIAL`}
</CodeBlock>

### FAILED

**Definition:** Run couldn't complete - no tests OR all tests had execution errors

**When assigned:**

- `total_tests == 0` (no tests in the run), OR
- `execution_errors == total_tests` (all tests errored)

**Email status:** `"failed"`

**Example scenarios:**

<CodeBlock filename="failed-scenarios.txt" language="text">
{`0 tests, 0 passed, 0 failed, 0 errors → FAILED (no tests)
10 tests, 0 passed, 0 failed, 10 errors → FAILED (all errored)`}
</CodeBlock>

### PROGRESS

**Definition:** Test run is currently executing

**When assigned:**

- Set when test execution starts
- Replaced by COMPLETED/PARTIAL/FAILED when execution finishes

---

## Status Determination Logic

The status is determined in the chord callback (`collect_results`) after all tests complete:

<CodeBlock filename="status-determination-logic.py" language="python">
{`# 1. No tests at all → FAILED
if total_tests == 0:
    status = "Failed"

# 2. All tests executed → COMPLETED
elif execution_errors == 0:
    status = "Completed"

# 3. All tests errored → FAILED
elif execution_errors == total_tests:
    status = "Failed"

# 4. Mixed results → PARTIAL
else:
    status = "Partial"`}
</CodeBlock>

**Implementation:** `apps/backend/src/rhesis/backend/tasks/execution/result_processor.py`

---

## Key Distinctions

### Test Run Status vs Test Result Status

| Aspect        | Test Run Status                      | Test Result Status        |
| ------------- | ------------------------------------ | ------------------------- |
| **Scope**     | Entire test run                      | Individual test           |
| **Purpose**   | Did tests execute?                   | Did test pass assertions? |
| **Values**    | COMPLETED, PARTIAL, FAILED, PROGRESS | Pass, Fail                |
| **Considers** | Execution errors                     | Metric success            |

### Execution Errors

**What are execution errors?**

- Tests that couldn't execute due to technical issues
- Missing test_metrics or empty metrics
- Infrastructure/connection failures
- Code errors during test execution

**What are NOT execution errors?**

- Tests that executed but failed assertions
- Metrics that returned `is_successful: false`
- Expected test failures

---

## Examples

### Scenario 1: Successful Test Run

<CodeBlock filename="scenario-successful.txt" language="text">
{`Total: 10 tests
Passed: 10
Failed: 0
Execution Errors: 0

Run Status: COMPLETED
Email Status: success
Reason: All tests executed and passed`}
</CodeBlock>

### Scenario 2: Tests Failed Assertions

<CodeBlock filename="scenario-failed-assertions.txt" language="text">
{`Total: 10 tests
Passed: 7
Failed: 3
Execution Errors: 0

Run Status: COMPLETED
Email Status: failed
Reason: All tests executed (even though some failed)`}
</CodeBlock>

### Scenario 3: Incomplete Execution

<CodeBlock filename="scenario-incomplete.txt" language="text">
{`Total: 10 tests
Passed: 5
Failed: 3
Execution Errors: 2

Run Status: PARTIAL
Email Status: partial
Reason: 2 tests couldn't execute`}
</CodeBlock>

### Scenario 4: Complete Failure

<CodeBlock filename="scenario-complete-failure.txt" language="text">
{`Total: 10 tests
Passed: 0
Failed: 0
Execution Errors: 10

Run Status: FAILED
Email Status: failed
Reason: No tests could execute`}
</CodeBlock>

### Scenario 5: Empty Test Run

<CodeBlock filename="scenario-empty-run.txt" language="text">
{`Total: 0 tests
Passed: 0
Failed: 0
Execution Errors: 0

Run Status: FAILED
Email Status: failed
Reason: No tests in the run`}
</CodeBlock>

---

## Statistics Calculation

Test statistics are calculated by analyzing `test_metrics`:

<CodeBlock filename="statistics-calculation.py" language="python">
{`def get_test_statistics(test_run, db):
    for result in test_results:
        metrics = result.test_metrics.get('metrics', {})

        # Check if ALL metrics passed
        all_metrics_passed = all(
            metric.get('is_successful', False)
            for metric in metrics.values()
        )

        if all_metrics_passed:
            tests_passed += 1
        else:
            tests_failed += 1`}
</CodeBlock>

**Source of Truth:** `test_metrics.metrics[].is_successful`

**NOT Used:** The `status` field in test results (historically unreliable)

---

## Email Notifications

Email notifications show test counts based on the same logic:

- **Total Tests:** Count of all test results
- **Tests Passed:** Tests where ALL metrics passed
- **Tests Failed:** Tests where ANY metric failed
- **Execution Errors:** Tests with no/empty metrics (shown separately if > 0)

**Template:** `apps/backend/src/rhesis/backend/notifications/email/templates/test_execution_summary.html.jinja2`

---

## Related Documentation

- [Test Result Status](/development/backend/test-result-status) - How individual test statuses are determined
- [Test Result Stats](/development/backend/test-result-stats) - Statistics APIs
- [Background Tasks](/development/backend/background-tasks) - Test execution flow
- [Email Notifications](/development/backend/email-notifications) - Email system

---

## Implementation Files

| File                                                               | Purpose                    |
| ------------------------------------------------------------------ | -------------------------- |
| `tasks/execution/result_processor.py`                              | Status determination logic |
| `tasks/enums.py`                                                   | RunStatus enum definition  |
| `app/constants.py`                                                 | Status mapping constants   |
| `notifications/email/templates/test_execution_summary.html.jinja2` | Email template             |
