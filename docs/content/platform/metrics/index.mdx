# Metrics

Define and manage evaluation criteria for testing AI responses with LLM-based grading.

<Callout type="default">
  **What are Metrics?** Metrics are quantifiable measurements that evaluate AI behavior and determine if requirements are met.
</Callout>

## Metrics at a glance

Metrics are organized by **Behaviors**, which are groups of related metrics. Example of behaviors are, for instance:

- **Accuracy**: Metrics for factual correctness
- **Tone**: Metrics for appropriate communication style
- **Safety**: Metrics for harmful content detection
- **Relevance**: Metrics for on-topic responses

You can add an existing metric to a behavior by clicking the "+" icon in the top-right corner of the chip on the Metrics Overview page.

![Metrics Assign](/screenshots/rhesis-ai-metrics-assign.png)



### Example of Existing Metrics

The platform includes pre-built metrics from Rhesis, DeepEval, and Ragas. Here are some examples:

| Metric Name | Provider | Score Type | Scope | Behavior | Description |
|-------------|----------|------------|-------|----------|-------------|
| Role Adherence | DeepEval | Numeric | Multi-Turn | Compliance | Evaluates whether the assistant maintains its assigned role throughout the conversation. |
| Knowledge Retention | Rhesis | Numeric | Multi-Turn | Reliability | Measures memory consistency and correct use of information introduced earlier in the conversation. |
| Answer Accuracy | Ragas | Numeric | Single-Turn | Reliability | Measures accuracy of the generated answer against ground truth. |


## Creating Metrics

Besides the metrics already provided in the platform, you can create your own custom metrics.

### Evaluation Process

Define how the LLM will evaluate responses:

**Evaluation Prompt**

Write clear instructions on what to evaluate. Be specific about the criteria.

Example: "Evaluate whether the response is accurate, complete, and relevant. Use the following criteria: accuracy of facts, coverage of required points, clarity of explanation."

**Evaluation Steps**

Break down the evaluation into steps. These steps will not be executed sequentially, but they provide clear guidance for the LLM to follow when producing a score and reasoning.

Example steps:
1. Check Accuracy: Identify any factual errors or unsupported statements.
2. Check Coverage: Determine if all required elements or sub-questions are addressed.
3. Check Clarity: Assess whether the response is clear and well-structured.

**Reasoning Instructions**

Explain how the evaluation should be reasoned about. Include key aspects to consider.

Example: "For each response, first extract the key claims or points. Assess the overall completeness, correctness and clarity, weighing each issue according to its importance. Use this structured reasoning to determine the final score"

**Best Practices:**
- Keep prompts focused on one evaluation dimension (accuracy, tone, safety, etc.)
- Use concrete, measurable criteria rather than vague terms
- Provide clear examples in your prompts when possible

### Score Configuration

Choose how your metric will evaluate responses:

**Numeric Scoring**

Define a numeric scale with a pass/fail threshold:

- **Minimum Score**: (e.g., 1)
- **Maximum Score**: (e.g., 10)
- **Threshold**: Set the passing criteria (e.g., 7)
- **Operator**: Choose comparison operator (greater than or equal, greater than, less than or equal, less than, equal to)

Example: Min 0, Max 10, Threshold 7 with "greater than or equal" operator means scores of 7-10 pass, 0-6 fail.

**Categorical Scoring**

Define custom categories the LLM can return:

- Add categories like "Excellent", "Good", "Fair", "Poor"
- Press Enter or comma to add each category
- The LLM will classify responses into one of these categories

Example: Categories could be "Safe", "Borderline", "Unsafe" for safety metrics.

### Metric Scope

Select which test types this metric applies to (at least one required):

- **Single-Turn**: Evaluates individual question-answer pairs
- **Multi-Turn**: Evaluates conversations across multiple exchanges

### Result Explanation

Provide instructions on how the LLM should explain the reasoning behind the score. This helps users understand why a particular score was given.

Example: "Explain which specific parts of the response were accurate or inaccurate, citing evidence from the context provided."

## Managing Metrics

- **View Details**: See all metric information organized in sections
- **Edit Metrics**: Update any field using the "Edit" button, then save
- **Delete Metrics**: Click "Delete Metric" and confirm
- **Assign to Behaviors**: From the Directory tab, select "Assign" and choose a behavior
- **Filter & Search**: Use search bar, backend type, metric type, or score type filters


## Practical Examples

Here are common metric use cases organized by behavior:

### Accuracy & Reliability

- **Knowledge Retention**: Memory consistency across conversation turns
- **Contextual Coherence**: Logical consistency across turns
- **Answer Accuracy**: Correctness vs. ground truth

### Compliance & Safety

- **Role Adherence**: Following assigned role
- **Personal Safety Detection**: Identifying unsafe content
- **Jailbreak Detection**: Preventing prompt injection attacks

### SQL & Task-Specific

- **SQL Execution Safety & Efficiency**: Query optimization and security
- **SQL Correctness**: Accurate query generation
- **Contextual Relevancy**: Task-appropriate responses

These examples can be used as templates to create your own metrics for single-turn or multi-turn evaluation.

---

<Callout type="default">
  **Next Steps** - Use metrics in [Tests](/platform/tests-generation) by
  assigning them to behaviors - View metric performance in [Test
  Results](/platform/test-results)
</Callout>
