import { CodeBlock } from '@/components/CodeBlock'

# Architecture

Penelope follows a clean, modular architecture designed for extensibility and reliability.

## System Overview

<CodeBlock filename="Architecture" isTerminal={true}>
{`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PenelopeAgent ğŸ¦¸â€â™€ï¸                â”‚
â”‚  Orchestrates multi-turn testing        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€ Test Configuration
           â”‚   â”œâ”€â”€ Goal (what to achieve)
           â”‚   â”œâ”€â”€ Instructions (how to test)
           â”‚   â””â”€â”€ Context (resources)
           â”‚
           â”œâ”€â”€ Target Abstraction
           â”‚   â””â”€â”€ EndpointTarget (Rhesis)
           â”‚
           â”œâ”€â”€ Tool System
           â”‚   â”œâ”€â”€ TargetInteractionTool
           â”‚   â”œâ”€â”€ AnalysisTool
           â”‚   â””â”€â”€ Custom Tools
           â”‚
           â””â”€â”€ Evaluation & Stopping
               â”œâ”€â”€ LLM-based goal checking
               â”œâ”€â”€ Max iterations
               â””â”€â”€ Timeout`}
</CodeBlock>

## Core Components

### PenelopeAgent

Main orchestrator coordinating test execution:

<CodeBlock filename="agent_flow.py" language="python">
{`# Agent manages the entire test lifecycle
agent = PenelopeAgent(model=model, max_iterations=10)

result = agent.execute_test(
    target=target,
    goal="Test goal",
    instructions="Optional instructions"
)

# Result contains full execution history
print(result.status)        # success, failure, error, timeout
print(result.goal_achieved)  # True/False
print(result.history)       # Full conversation`}
</CodeBlock>

### TurnExecutor

Handles individual turn execution - reasoning, tool selection, and execution.

### GoalEvaluator

LLM-based evaluation of goal achievement using structured output.

### Targets

Abstraction for systems under test:

<CodeBlock filename="targets.py" language="python">
{`from rhesis.penelope import EndpointTarget

# Rhesis endpoints
target = EndpointTarget(endpoint_id="your-endpoint-id")

# Future: LangChain, CrewAI, custom targets
# target = LangChainTarget(chain=my_chain)
# target = CrewAITarget(agent=my_agent)`}
</CodeBlock>

### Tools

Penelope uses three built-in tools:

**1. Send Message to Target** - Interacts with the system under test

**2. Analyze Response** - Evaluates target responses for goal criteria

**3. Extract Information** - Pulls specific data from responses

Add custom tools for specialized testing:

<CodeBlock filename="custom_tool.py" language="python">
{`from rhesis.penelope.tools.base import Tool, ToolResult

class CustomTool(Tool):
    @property
    def name(self) -> str:
        return "my_custom_tool"
    
    @property
    def description(self) -> str:
        return "Detailed description with examples..."
    
    def execute(self, **kwargs) -> ToolResult:
        # Your logic
        return ToolResult(success=True, output={...})

agent = PenelopeAgent(tools=[CustomTool()])`}
</CodeBlock>

## Execution Flow

1. **Initialize** - Agent receives goal, instructions, and context
2. **Turn Loop** - For each turn up to max_iterations:
   - Agent reasons about current state
   - Selects and executes tool
   - Processes result
   - Evaluates goal achievement
   - Checks stopping conditions
3. **Completion** - Returns TestResult with full history

<CodeBlock filename="execution_detail.py" language="python">
{`# Each turn produces structured output
for turn in result.history:
    print(f"Turn {turn.turn_number}")
    print(f"Reasoning: {turn.reasoning}")
    print(f"Action: {turn.action}")
    print(f"Output: {turn.action_output}")
    print(f"Goal Progress: {turn.goal_progress}")`}
</CodeBlock>

## Prompt System

Penelope uses Jinja2 templates for prompts:

- **System Prompt** - Core agent instructions and capabilities
- **Turn Prompts** - Context-aware prompting for each turn
- **Evaluation Prompts** - Structured goal assessment

Located in `src/rhesis/penelope/prompts/`:

<CodeBlock filename="prompt_structure" isTerminal={true}>
{`prompts/
â”œâ”€â”€ system_prompt.j2       # Agent instructions
â”œâ”€â”€ turn/
â”‚   â”œâ”€â”€ first_turn.j2      # Initial turn
â”‚   â””â”€â”€ subsequent_turn.j2 # Follow-up turns
â”œâ”€â”€ evaluation/
â”‚   â””â”€â”€ goal_eval.j2       # Goal checking
â””â”€â”€ tools/
    â””â”€â”€ tool_descriptions.py  # Tool documentation`}
</CodeBlock>

## Stopping Conditions

Tests stop when any condition is met:

1. **Goal Achieved** - LLM evaluates goal is met
2. **Max Iterations** - Reached iteration limit
3. **Timeout** - Exceeded time limit
4. **Error** - Unrecoverable error occurred

<CodeBlock filename="stopping.py" language="python">
{`agent = PenelopeAgent(
    max_iterations=20,      # Stop after 20 turns
    timeout_seconds=300     # Stop after 5 minutes
)

result = agent.execute_test(target=target, goal="...")

# Check why it stopped
if result.status == "success" and result.goal_achieved:
    print("Goal achieved!")
elif result.status == "failure":
    print("Max iterations reached")
elif result.status == "timeout":
    print("Time limit exceeded")
elif result.status == "error":
    print(f"Error: {result.error}")`}
</CodeBlock>

## Type Safety

Pydantic models ensure type safety throughout:

- **TestState** - Current test state
- **Turn** - Individual turn data
- **TestResult** - Final test outcome
- **ToolResult** - Tool execution result
- **Schemas** - Structured LLM outputs

## Design Principles

1. **Modularity** - Clear separation of concerns (agent, executor, evaluator, tools)
2. **Extensibility** - Easy to add custom tools and targets
3. **Observability** - Full transparency into reasoning and execution
4. **Type Safety** - Pydantic validation throughout
5. **Provider Agnostic** - Works with any LLM provider

---

<Callout type="default">
  **Next:** Learn about [Custom Tools](/penelope/custom-tools) or check out [Use Cases](/penelope/use-cases) for practical examples.
</Callout>
