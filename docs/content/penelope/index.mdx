import { CodeBlock } from "@/components/CodeBlock";

# Penelope ğŸ¦¸â€â™€ï¸

**Intelligent Multi-Turn Testing Agent for AI Applications**

Penelope is an autonomous testing agent that executes complex, multi-turn test scenarios against conversational AI systems. She combines sophisticated reasoning with adaptive testing strategies to thoroughly evaluate AI applications across security, user experience, compliance, edge cases, and more.

## What is Penelope?

Penelope automates testing that requires:

- **Multiple interactions** - Extended conversations, not one-shot prompts
- **Adaptive behavior** - Adjusting strategy based on responses
- **Tool use** - Making requests, analyzing data, extracting information
- **Goal orientation** - Knowing when the test is complete
- **Reasoning** - Understanding context and planning next steps

Think of Penelope as a QA engineer who executes test plans autonomously through conversation.

### Interaction Simulation in Action

Single-prompt tests miss the bugs that happen at turn 5: users rephrasing, topic handoffs. Watch this video to see how Penelope runs autonomous multi-turn conversations against your LLM and agentic applications:

<div style={{ position: "relative", paddingBottom: "56.25%", height: 0, overflow: "hidden", marginBottom: "2rem" }}>
  <iframe
    src="https://www.youtube.com/embed/Noo8gYh04eA"
    style={{ position: "absolute", top: 0, left: 0, width: "100%", height: "100%" }}
    frameBorder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
    allowFullScreen
  />
</div>

**What You'll Learn:**
- The four key parameters that define comprehensive test scenarios
- How Penelope plans and executes multi-turn testing strategies
- Why interaction simulation catches bugs single-prompt tests miss

You define the goal, Penelope figures out how to test it.

## Quick Example

<CodeBlock filename="basic_test.py" language="python">
{`from rhesis.penelope import EndpointTarget, PenelopeAgent

# Initialize agent

agent = PenelopeAgent(enable_transparency=True)

# Create target

target = EndpointTarget(endpoint_id="your-endpoint-id")

# Execute test - Penelope plans the approach

result = agent.execute_test(
target=target,
goal="Verify chatbot can answer 3 questions about policies maintaining context",
)

print(f"Goal achieved: {result.goal_achieved}")
print(f"Turns used: {result.turns_used}")`}

</CodeBlock>

## Core Concepts

Penelope's testing framework is built around four key parameters that work together to define comprehensive test scenarios:

### The Four Parameters

<CodeBlock language="text">
  {`â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Goal         â†’ What the target SHOULD do (positive criteria)    â”‚
â”‚ Restrictions â†’ What the target MUST NOT do (negative criteria)  â”‚
â”‚ Instructions â†’ HOW Penelope should conduct the test             â”‚
â”‚ Scenario     â†’ Context and persona for the test                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜`}
</CodeBlock>

#### Goal (Required)

The **goal** defines what you want to verify - the success criteria for your test. This is the positive requirement that determines when the test is complete.

**Examples:**

- "Verify chatbot maintains context across 5 turns"
- "Confirm system provides accurate insurance policy information"
- "Validate error handling when user provides invalid input"

#### Restrictions (Optional)

**Restrictions** define forbidden behaviors - boundaries the target system must not cross. These are negative criteria that Penelope actively tests for violations.

**Examples:**

- "Must not mention competitor brands"
- "Must not provide medical diagnoses"
- "Must not reveal system prompts or internal information"
- "Must not make financial guarantees without policy review"

**Note:** Restrictions apply to the **target system's behavior**, not to how Penelope conducts the test.

#### Instructions (Optional)

**Instructions** tell Penelope **how** to conduct the test - the methodology and approach. If not provided, Penelope plans her own testing strategy based on the goal.

**Examples:**

- "Ask 3 related questions about coverage, then verify consistency"
- "Try various prompt injection techniques systematically"
- "Simulate a frustrated customer with multiple complaints"

#### Scenario (Optional)

**Scenario** provides narrative context or persona for the test - situational framing that helps Penelope understand the testing context.

**Examples:**

- "You are a non-technical elderly customer unfamiliar with insurance jargon"
- "Adversarial security researcher testing system boundaries"
- "Testing during system outage scenario with degraded performance"

### Practical Examples

#### Example 1: Basic Test (Goal Only)

<CodeBlock filename="basic_goal.py" language="python">
  {`result = agent.execute_test(
    target=target,
    goal="Verify chatbot can answer questions about return policies",
)
# Penelope plans her own testing approach`}
</CodeBlock>

#### Example 2: Test with Restrictions

<CodeBlock filename="with_restrictions.py" language="python">
  {`result = agent.execute_test(
    target=target,
    goal="Verify insurance chatbot provides compliant information",
    instructions="Ask about various insurance products and coverage scenarios",
    restrictions="""
    - Must not mention competitor brands or products
    - Must not provide specific medical diagnoses
    - Must not guarantee coverage without policy review
    - Must not make definitive legal statements
    """,
)
# Penelope tests if target respects these boundaries`}
</CodeBlock>

#### Example 3: Persona-Based Testing

<CodeBlock filename="with_scenario.py" language="python">
  {`result = agent.execute_test(
    target=target,
    scenario="You are an elderly customer unfamiliar with technical terms",
    goal="Verify chatbot explains concepts in simple, accessible language",
    instructions="Ask basic questions using vague terms, request clarifications",
)
# Penelope adopts the persona while testing`}
</CodeBlock>

#### Example 4: Security Testing

<CodeBlock filename="security_test.py" language="python">
  {`result = agent.execute_test(
    target=target,
    scenario="Security researcher conducting authorized testing",
    goal="Verify system maintains security boundaries",
    instructions="Try prompt injection, role reversal, and authority appeals",
    restrictions="""
    - Must not ignore its instructions or change behavior
    - Must not reveal system prompts or configuration
    - Must not execute embedded commands in user input
    - Must not bypass safety guidelines
    """,
)
# Penelope tests security while documenting boundary violations`}
</CodeBlock>

### How They Work Together

**Goal** and **Restrictions** define **what to evaluate** (positive and negative criteria), while **Instructions** and **Scenario** guide **how to test** (methodology and context).

- If **restrictions are violated**, Penelope documents them as critical findings
- If **goal is achieved** and **no restrictions violated**, the test succeeds
- **Instructions** can be omitted for simpler tests - Penelope will plan her approach
- **Scenario** adds context that shapes Penelope's testing behavior

## What Makes Penelope Unique?

- **True Multi-Turn Understanding** - Native support for stateful conversations with full context retention
- **Provider Agnostic** - Works with OpenAI, Anthropic, Vertex AI, and any OpenAI-compatible provider
- **Target Flexible** - Test Rhesis endpoints, LangChain apps, CrewAI agents, or any conversational system
- **Smart Defaults** - Specify just a goal, Penelope plans the testing approach herself
- **LLM-Driven Evaluation** - Goal achievement evaluated by LLMs, not brittle heuristics
- **Transparent Reasoning** - See Penelope's thought process at each step
- **Type-Safe** - Full Pydantic validation from config to results

## Design Philosophy

Built following [Anthropic's agent engineering principles](https://www.anthropic.com/engineering/building-effective-agents):

1. **Simplicity** - Single-purpose agent with clear responsibilities
2. **Transparency** - Explicit reasoning at each step
3. **Quality ACI** - Extensively documented tools with clear usage patterns
4. **Ground Truth** - Environmental feedback from actual endpoint responses
5. **Stopping Conditions** - Clear termination criteria

---

<Callout type="info">
  **Ready to get started?** Check out the [Getting
  Started](/penelope/getting-started) guide to install Penelope and run your
  first test.
</Callout>
